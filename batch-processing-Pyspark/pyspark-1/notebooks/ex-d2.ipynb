{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04ea709e-18f3-4b31-ac0a-7964ca1d8f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 15.0\n"
     ]
    }
   ],
   "source": [
    "##1 Create an RDD from [5, 10, 15, 20, 25] and compute the average value.\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Initialize Spark context\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# Create an RDD from a Python list\n",
    "numbers = [5, 10, 15, 20, 25]\n",
    "rdd = sc.parallelize(numbers)  # parallelize converts list to RDD\n",
    "\n",
    "# Compute the sum of all numbers using reduce\n",
    "total_sum = rdd.reduce(lambda x, y: x + y)  # reduce applies the lambda cumulatively\n",
    "\n",
    "# Count the total number of elements in the RDD\n",
    "count = rdd.count() \n",
    "\n",
    "# Compute the average\n",
    "average = total_sum / count\n",
    "\n",
    "# Print the result\n",
    "print(\"Average:\", average)  # Output: Average: 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82019e52-84f5-4369-bf5f-f29fa1efe655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values: 5\n"
     ]
    }
   ],
   "source": [
    "##2 Create an RDD from [1, 2, 2, 3, 4, 4, 5] and count distinct numbers.\n",
    "\n",
    "\n",
    "# Create an RDD from a Python list\n",
    "numbers = [1, 2, 2, 3, 4, 4, 5]\n",
    "rdd = sc.parallelize(numbers)  # Convert list to RDD\n",
    "\n",
    "# Get distinct values and count them\n",
    "distinct_count = rdd.distinct().count()\n",
    "\n",
    "# distinct() removes duplicates\n",
    "# count() returns total unique elements\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of distinct values:\", distinct_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "380e0c04-5144-496e-8de1-97900524285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number: 10\n"
     ]
    }
   ],
   "source": [
    "##3 Create an RDD from [3, 8, 2, 10, 6] and find the maximum number.\n",
    "\n",
    "\n",
    "# Create an RDD from a Python list\n",
    "numbers = [3, 8, 2, 10, 6]\n",
    "rdd = sc.parallelize(numbers)  # Convert list to RDD\n",
    "\n",
    "# Find the maximum value using reduce\n",
    "max_num = rdd.reduce(lambda a, b: a if a > b else b)  \n",
    "# Compare elements pairwise, keep the larger one\n",
    "\n",
    "# Print the maximum value\n",
    "print(\"Maximum number:\", max_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a9b3f0-472a-4ca2-9293-97d90f42dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total new cases for Afghanistan: 235214.0\n"
     ]
    }
   ],
   "source": [
    "##4 Load covid-dataset/covid-data.csv, filter for Afghanistan (iso_code = 'AFG'), \n",
    "    # and compute total new_cases.\n",
    "\n",
    "\n",
    "# Load CSV file into an RDD (each line is a string)\n",
    "rdd = sc.textFile(\"covid-dataset/covid-data.csv\")  \n",
    "\n",
    "# Get the header row\n",
    "header = rdd.first()  \n",
    "\n",
    "# Filter out header and keep only Afghanistan data (iso_code == 'AFG')\n",
    "afg_data = rdd.filter(lambda row: row != header and row.startswith(\"AFG\"))  \n",
    "\n",
    "# Extract 'new_cases' column (6th column) and convert to float\n",
    "new_cases = afg_data.map(lambda row: float(row.split(',')[5] or 0.0))  \n",
    "\n",
    "# Compute total new cases\n",
    "total_cases = new_cases.sum()  \n",
    "\n",
    "# Display total new cases\n",
    "print(f\"Total new cases for Afghanistan: {total_cases}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1054b3bc-3a46-4c19-959b-6157f788e5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of factorials: 153\n"
     ]
    }
   ],
   "source": [
    "##5 Create an RDD from [1, 2, 3, 4, 5], compute factorials, and sum them.\n",
    "\n",
    "import math\n",
    "\n",
    "# Create an RDD from a Python list\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "rdd = sc.parallelize(numbers)  # parallelize converts list to RDD\n",
    "\n",
    "# Compute factorial of each number and sum them\n",
    "factorial_sum = (\n",
    "    rdd\n",
    "    .map(lambda x: math.factorial(x))  # map: compute factorial of each element\n",
    "    .reduce(lambda a, b: a + b)       # reduce: sum all factorials\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(\"Sum of factorials:\", factorial_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "639dbe56-9c01-45ca-b942-d057da1a8e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of cubes of odd numbers: 496\n"
     ]
    }
   ],
   "source": [
    "##6 Create an RDD from [1, 2, 3, 4, 5, 6, 7], filter odd numbers, cube them, and compute the sum.\n",
    "\n",
    "\n",
    "numbers = [1, 2, 3, 4, 5, 6, 7]\n",
    "rdd = sc.parallelize(numbers)\n",
    "\n",
    "# Keep only odd numbers, cube them, and sum the results\n",
    "result = (\n",
    "    rdd\n",
    "    .filter(lambda x: x % 2 != 0)   # Odd numbers only\n",
    "    .map(lambda x: x**3)            # Cube each\n",
    "    .reduce(lambda a, b: a + b)     # Sum all cubes\n",
    ")\n",
    "\n",
    "print(\"Sum of cubes of odd numbers:\", result) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d979b72-0df1-4b23-bc7a-8fdee9748841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 26525), ('Europe', 91031), ('Africa', 95419), ('North America', 68638), ('South America', 23440), ('Asia', 84199), ('Oceania', 40183)]\n"
     ]
    }
   ],
   "source": [
    "##7 Load covid-dataset/covid-data.csv, group by continent, and count records per continent.\n",
    "\n",
    "\n",
    "rdd = sc.textFile(\"covid-dataset/covid-data.csv\")  # Load CSV\n",
    "header = rdd.first()  # Get header\n",
    "counts = (rdd\n",
    "          .filter(lambda row: row != header)              # Skip header\n",
    "          .map(lambda row: (row.split(',')[1], 1))        # (continent, 1)\n",
    "          .reduceByKey(lambda a, b: a + b))               # Sum per continent\n",
    "\n",
    "print(counts.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dfe6d72-d71c-4d07-9694-9ad1a7ddef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('S2', ('Bob', 90)), ('S1', ('Alice', 85))]\n"
     ]
    }
   ],
   "source": [
    "##8 Create RDDs: [('S1', 'Alice'), ('S2', 'Bob'), ('S3', 'Charlie')] and [('S1', 85), ('S2', 90),\n",
    "    #('S4', 95)]. Join on student ID and collect results.\n",
    "\n",
    "\n",
    "students = sc.parallelize([('S1','Alice'), ('S2','Bob'), ('S3','Charlie')])  # RDD of student IDs & names\n",
    "grades = sc.parallelize([('S1',85), ('S2',90), ('S4',95)])                 # RDD of student IDs & grades\n",
    "\n",
    "joined_rdd = students.join(grades)  # Join on student ID (key)\n",
    "\n",
    "print(joined_rdd.collect())  # Collect joined RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b1ab714-efa3-448d-b998-fe5077aabcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average new deaths for Brazil: 22408.555053763415\n"
     ]
    }
   ],
   "source": [
    "##9 Load covid-dataset/covid-data.csv, filter for Brazil (iso_code = 'BRA'), cache, \n",
    "    # and compute average new_deaths.\n",
    "\n",
    "\n",
    "rdd = sc.textFile(\"covid-dataset/covid-data.csv\")  # Load CSV\n",
    "header = rdd.first()                               # Get header\n",
    "bra_data = rdd.filter(lambda row: row != header and row.startswith(\"BRA\")).cache()  # Filter Brazil, cache\n",
    "\n",
    "new_deaths = bra_data.map(lambda row: float(row.split(',')[6] or 0.0))  # Extract new_deaths column\n",
    "count = new_deaths.count()                                             # Count rows\n",
    "total = new_deaths.sum()                                               # Sum of new_deaths\n",
    "average = total / count if count > 0 else 0.0                          # Compute average\n",
    "\n",
    "print(f\"Average new deaths for Brazil: {average}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "694a6632-2cf5-49fc-b8fa-b7e7be2ccdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apple', 8), ('orange', 8), ('banana', 2)]\n"
     ]
    }
   ],
   "source": [
    "##10 Create an RDD from [('apple', 5), ('banana', 2), ('orange', 8), ('apple', 3)].\n",
    "    # Sum values by key and sort by value descending.\n",
    "\n",
    "data = [('apple',5), ('banana',2), ('orange',8), ('apple',3)]\n",
    "rdd = sc.parallelize(data)                        # Create RDD of key-value pairs\n",
    "\n",
    "summed_rdd = rdd.reduceByKey(lambda a, b: a + b)  # Sum values by key\n",
    "sorted_rdd = summed_rdd.sortBy(lambda x: x[1], ascending=False)  # Sort by value descending\n",
    "\n",
    "print(sorted_rdd.collect())  # Collect sorted RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb6af0-17bb-4e04-a296-7e3511d03bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
